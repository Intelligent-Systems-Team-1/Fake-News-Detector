{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc3a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e613b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_bert(texts, labels, model_name: str = \"bert-base-uncased\", epochs: int = 3, batch_size: int = 8, lr: float = 2e-5, max_length: int = 512):\n",
    "    unique_labels = sorted(set(labels))\n",
    "    label2id = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    id2label = {i: lab for lab, i in label2id.items()}\n",
    "    label_ids = [label2id[lab] for lab in labels]\n",
    "    target_names = [str(l) for l in unique_labels]\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        texts, label_ids,\n",
    "        stratify=label_ids,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    def encode(batch):\n",
    "        return tokenizer(\n",
    "            list(batch),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    train_enc = encode(X_tr)\n",
    "    test_enc  = encode(X_te)\n",
    "\n",
    "    train_ds = TensorDataset(\n",
    "        train_enc.input_ids,\n",
    "        train_enc.attention_mask,\n",
    "        torch.tensor(y_tr, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "    test_ds = TensorDataset(\n",
    "        test_enc.input_ids,\n",
    "        test_enc.attention_mask,\n",
    "        torch.tensor(y_te, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_labels), id2label=id2label, label2id=label2id).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        for input_ids, attn_mask, labs in train_loader:\n",
    "            input_ids, attn_mask, labs = ( input_ids.to(device), attn_mask.to(device), labs.to(device) )\n",
    "            loss = model(input_ids=input_ids, attention_mask=attn_mask, labels=labs).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Average loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attn_mask, labs in test_loader:\n",
    "            input_ids, attn_mask = input_ids.to(device), attn_mask.to(device)\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attn_mask\n",
    "            ).logits\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().tolist())\n",
    "            trues.extend(labs.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(trues, preds)\n",
    "    f1_w     = f1_score(trues, preds, average=\"weighted\")\n",
    "    report   = classification_report(trues, preds, target_names=target_names)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1_w,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "    return tokenizer, model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6af033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average loss: 0.1546\n",
      "\n",
      "Epoch 2/3\n",
      "Average loss: 0.1385\n",
      "\n",
      "Epoch 3/3\n",
      "Average loss: 0.1082\n",
      "\n",
      "Accuracy:    0.9152219140083218\n",
      "Weighted F1: 0.9151204299319851\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      5825\n",
      "           1       0.88      0.95      0.92      5711\n",
      "\n",
      "    accuracy                           0.92     11536\n",
      "   macro avg       0.92      0.92      0.92     11536\n",
      "weighted avg       0.92      0.92      0.92     11536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../cleaned_datasets/cleaned_news_binary_bert.csv\")\n",
    "tok, model, stats = train_evaluate_bert(df[\"text\"], df[\"label\"])\n",
    "\n",
    "print(\"\\nAccuracy:   \", stats[\"accuracy\"])\n",
    "print(\"Weighted F1:\", stats[\"f1_weighted\"])\n",
    "print(\"\\nReport:\\n\", stats[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d71747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average loss: 0.3906\n",
      "\n",
      "Epoch 2/3\n",
      "Average loss: 0.3589\n",
      "\n",
      "Epoch 3/3\n",
      "Average loss: 0.3037\n",
      "\n",
      "Accuracy:    0.834864771151179\n",
      "Weighted F1: 0.8261187088768973\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      5196\n",
      "           1       0.89      0.95      0.92      4694\n",
      "           2       0.28      0.19      0.22       491\n",
      "           3       0.25      0.33      0.29       526\n",
      "           4       0.24      0.17      0.20       420\n",
      "           5       0.37      0.11      0.16       209\n",
      "\n",
      "    accuracy                           0.83     11536\n",
      "   macro avg       0.49      0.45      0.45     11536\n",
      "weighted avg       0.82      0.83      0.83     11536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../cleaned_datasets/cleaned_news_multinomial_bert.csv\")\n",
    "tok1, model1, stats1 = train_evaluate_bert(df[\"text\"], df[\"label\"])\n",
    "\n",
    "print(\"\\nAccuracy:   \", stats1[\"accuracy\"])\n",
    "print(\"Weighted F1:\", stats1[\"f1_weighted\"])\n",
    "print(\"\\nReport:\\n\", stats1[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ad6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "def train_evaluate_bert_oversampling(texts, labels, model_name: str = \"bert-base-uncased\", epochs: int = 3, batch_size: int = 8, lr: float = 2e-5, test_size: float = 0.2, random_state: int = 42, max_length: int = 512):\n",
    "    unique_labels = sorted(set(labels))\n",
    "    label2id = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    id2label = {i: lab for lab, i in label2id.items()}\n",
    "    label_ids = [label2id[lab] for lab in labels]\n",
    "    target_names = [str(l) for l in unique_labels]\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(texts, label_ids, stratify=label_ids, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    X_tr_arr = np.array(X_tr).reshape(-1, 1)\n",
    "    X_res, y_res = ros.fit_resample(X_tr_arr, y_tr)\n",
    "    X_res = X_res.flatten().tolist()\n",
    "\n",
    "    print(\"Resampled training counts:\", {lab: y_res.count(i) \n",
    "          for lab,i in label2id.items()})\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    def encode(batch_texts):\n",
    "        return tokenizer(\n",
    "            batch_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    train_enc = encode(X_res)\n",
    "    test_enc  = encode(list(X_te))\n",
    "\n",
    "    train_ds = TensorDataset(\n",
    "        train_enc.input_ids,\n",
    "        train_enc.attention_mask,\n",
    "        torch.tensor(y_res, dtype=torch.long)\n",
    "    )\n",
    "    test_ds = TensorDataset(\n",
    "        test_enc.input_ids,\n",
    "        test_enc.attention_mask,\n",
    "        torch.tensor(y_te, dtype=torch.long)\n",
    "    )\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(unique_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    ).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        for input_ids, attn_mask, labs in train_loader:\n",
    "            input_ids, attn_mask, labs = (\n",
    "                input_ids.to(device),\n",
    "                attn_mask.to(device),\n",
    "                labs.to(device)\n",
    "            )\n",
    "            loss = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attn_mask,\n",
    "                labels=labs\n",
    "            ).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Average loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attn_mask, labs in test_loader:\n",
    "            input_ids, attn_mask = input_ids.to(device), attn_mask.to(device)\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attn_mask\n",
    "            ).logits\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().tolist())\n",
    "            trues.extend(labs.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(trues, preds)\n",
    "    f1_w     = f1_score(trues, preds, average=\"weighted\")\n",
    "    report   = classification_report(trues, preds, target_names=target_names)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1_w,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "    return tokenizer, model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746c9290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled training counts: {0: 20780, 1: 20780, 2: 20780, 3: 20780, 4: 20780, 5: 20780}\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average loss: 0.3813\n",
      "\n",
      "Epoch 2/3\n",
      "Average loss: 0.1004\n",
      "\n",
      "Epoch 3/3\n",
      "Average loss: 0.0702\n",
      "\n",
      "Accuracy:    0.827756588072122\n",
      "Weighted F1: 0.826214968332371\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      5196\n",
      "           1       0.87      0.95      0.91      4694\n",
      "           2       0.24      0.31      0.27       491\n",
      "           3       0.30      0.20      0.24       526\n",
      "           4       0.20      0.30      0.24       420\n",
      "           5       0.36      0.06      0.10       209\n",
      "\n",
      "    accuracy                           0.83     11536\n",
      "   macro avg       0.49      0.45      0.45     11536\n",
      "weighted avg       0.83      0.83      0.83     11536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../cleaned_datasets/cleaned_news_multinomial_bert.csv\")\n",
    "tok2, model2, stats2 = train_evaluate_bert_oversampling(df[\"text\"], df[\"label\"])\n",
    "\n",
    "print(\"\\nAccuracy:   \", stats2[\"accuracy\"])\n",
    "print(\"Weighted F1:\", stats2[\"f1_weighted\"])\n",
    "print(\"\\nReport:\\n\", stats2[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb86df33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/bert_pipeline\\\\tokenizer_config.json',\n",
       " '../models/bert_pipeline\\\\special_tokens_map.json',\n",
       " '../models/bert_pipeline\\\\vocab.txt',\n",
       " '../models/bert_pipeline\\\\added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/bert_pipeline\")\n",
    "tok.save_pretrained(\"../models/bert_pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
